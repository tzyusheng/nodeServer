# Node SDK文档

本文档主要介绍NLP Node SDK的安装和使用。在使用本文档前，您需要先了解自然语言处理（Natural Language Processing）的基础知识，并已经开通了服务。

# 安装NLP Node SDK

**NLP Node SDK目录结构**

        ├── src
        │  ├── auth                                //授权相关类
        │  ├── http                                //Http通信相关类
        │  ├── client                              //公用类
        │  ├── util                                //工具类
        │  └── const                               //常量类
        ├── AipNlp.js                              //NLP交互类
        ├── index.js                               //入口文件
        └── package.json                           //npm包描述文件


**支持 node 版本 4.0+**

**直接使用node开发包步骤如下：**

1.在[官方网站](http://ai.baidu.com/sdk)下载node SDK压缩包。

2.将下载的`aip-node-sdk-version.zip`解压后，复制到工程文件夹中。

3.进入目录，运行npm install安装sdk依赖库

4.把目录当做模块依赖

其中，`version`为版本号，添加完成后，用户就可以在工程中使用OCR Node SDK。

**直接使用npm安装依赖：**

暂无


# 快速入门

1.初始化一个AipNlpClient。

AipNlpClient是与Natural Language Processing（NLP）交互的客户端，所有NLP操作都是通过AipNlpClient完成的。您可以参考**新建AipNlpClient**，完成初始化客户端的操作。

## 新建AipNlpClient

新建AipNlpClient是Natural Language Processing的Node客户端，为使用Natural Language Processing的开发人员提供了一系列的交互方法。

用户可以参考如下代码新建一AipNlpClient：

```
var AipNlp = require("baidu-ai").nlp;

// 设置APPID/AK/SK
var APP_ID = "你的 App ID";
var API_KEY = "你的 Api ID";
var SECRET_KEY = "你的 Secret Key";

var client = new AipNlp(APP_ID, API_KEY, SECRET_KEY);
```

在上面代码中，常量`APP_ID`在百度云控制台中创建，常量`API_KEY`与`SECRET_KEY`是在创建完毕应用后，系统分配给用户的，均为字符串，用于标识用户，为访问做签名验证，可在AI服务控制台中的**应用列表**中查看。

**注意：**如您以前是百度云的老用户，其中`API_KEY`对应百度云的“Access Key ID”，`SECRET_KEY`对应百度云的“Access Key Secret”。


# 中文分词

举例，要对字符串'你好百度'进行分词：

```
client.wordseg('你好百度').then(function(result) {
    console.log(JSON.stringify(result));
});
```

**中文分词 请求参数详情**

| 参数      | 类型     | 描述                                     | 是否必须 |
| :------ | :----- | :------------------------------------- | :--- |
| query   | String | 待分词的文本                                 | 是    |

**中文分词 返回数据参数详情**

| 参数             | 类型     | 描述                                       |
| :------------- | :----- | :--------------------------------------- |
| wordsepbuf     | String | 基本词粒度结果，以\t分割                            |
| wsbtermcount   | Int    | 基本词粒度输出的词个数                              |
| wsbtermoffsets | Int[]  | 该参数为列表，元素个数为切分出来的词个数，每个元素值表示对应的基本词在被切分文本的起始位置（字节偏移） |
| wsbtermpos     | String | 参数值为列表，元素值为对应切分出来的基本词在 wordsepbuf的字节偏移以及长度，整数的低24bit为偏移，高8bit为长度 |
| wpcompbuf      | String | 混排粒度结果，以\t分割                             |
| wpbtermcount   | Int    | 混排粒度输出的词个数                               |
| wpbtermoffsets | Int[]  | 该参数为列表，元素个数为切分出来的词个数，每个元素值表示对应的词是从第几个基本词开始的（基本词偏移） |
| wpbtermpos     | Int[]  | 参数值为列表，元素值为对应切分出来的词在 wpcompbuf的字节偏移以及长度，整数的低24bit为偏移，高8bit为长度 |
| subphrbuf      | String | 所有识别出来的短语，以\t分割                          |
| spbtermcount   | Int    | 识别出来的短语个数                                |
| spbtermoffsets | Int[]  | 该参数为列表，元素个数为识别出来的短语个数，每个元素值表示对应短语是从第几个基本词开始的（基本词偏移） |
| spbtermpos     | Int[]  | 参数值为列表，元素值为对应切分出来的短语在 subphrbuf的字节偏移以及长度，整数的低24bit为偏移，高8bit为长度 |

# 词性标注

词性标注接口为分词结果中的每个单词标注一个正确的词性的程序，也标注每个词是名词、动词、形容词或其他词性。

举例，传入一个词识别词的词性：

```
client.wordpos('百度').then(function(result) {
    console.log(JSON.stringify(result));
});
```

**词性标注 请求参数详情**

| 参数    | 类型     | 描述         | 是否必须 |
| :---- | :----- | :--------- | :--- |
| query | String | 输入需要识别词性的词 | 是    |

**词性标注 返回数据参数详情**

| 参数          | 类型     | 含义及备注                              |
| ----------- | ------ | ---------------------------------- |
| result_out  | array  | 词性标注结果数组，数组中每个元素对应一个词汇。每个词汇是一个dict |
| +word       | string | 词汇的字面                              |
| +offset     | int    | 偏移量，以基本粒度词汇为单位                     |
| +length     | int    | 长度，以基本粒度词汇为单位                      |
| +type       | string | 词性                                 |
| +confidence | float  | 置信度分值，0~1                          |

**词性缩略词说明**

| type | 代码   | 名称   | 帮助记忆的诠释                      |
| ---- | ---- | ---- | ---------------------------- |
| 1    | Ag   | 形语素  | 形容词性语素。形容词代码为a，语素代码ｇ前面置以A    |
| 2    | Dg   | 副语素  | 副词性语素。副词代码为d，语素代码ｇ前面置以D。     |
| 3    | Ng   | 名语素  | 名词性语素。名词代码为n，语素代码ｇ前面置以N。     |
| 4    | Tg   | 时语素  | 时间词性语素。时间词代码为t,在语素的代码g前面置以T。 |
| 5    | Vg   | 动语素  | 动词性语素。动词代码为v。在语素的代码g前面置以V    |
| 6    | a    | 形容词  | 取英语形容词adjective的第1个字母        |
| 7    | ad   | 副形词  | 直接作状语的形容词。形容词代码a和副词代码d并在一起。  |
| 8    | an   | 名形词  | 具有名词功能的形容词。形容词代码a和名词代码n并在一起。 |
| 9    | b    | 区别词  | 取汉字“别”的声母。                   |
| 10   | c    | 连词   | 取英语连词conjunction的第1个字母。      |
| 11   | d    | 副词   | 取adverb的第2个字母，因其第1个字母已用于形容词。 |
| 12   | e    | 叹词   | 取英语叹词exclamation的第1个字母       |
| 13   | f    | 方位词  | 取汉字“方”                       |
| 14   | g    | 语素   | 绝大多数语素都能作为合成词的“词根”，取汉字“根”的声母 |
| 15   | h    | 前接成分 | 取英语head的第1个字母                |
| 16   | i    | 成语   | 取英语成语idiom的第1个字母             |
| 17   | j    | 简称略语 | 取汉字“简”的声母。                   |
| 18   | k    | 后接成分 |                              |
| 19   | l    | 习用语  | 习用语尚未成为成语，有点“临时性”，取“临”的声母。   |
| 20   | m    | 数词   | 取英语numeral的第3个字母，n，u已有他用。    |
| 21   | n    | 名词   | 取英语名词noun的第1个字母。             |
| 22   | nr   | 人名   | 名词代码n和“人(ren)”的声母并在一起。       |
| 23   | ns   | 地名   | 名词代码n和处所词代码s并在一起。            |
| 24   | nt   | 机构团体 | “团”的声母为t，名词代码n和t并在一起。        |
| 25   | nx   | 外文专名 | 一般是全角英文专名，如：ＺＢＴ              |
| 26   | nz   | 其他专名 | “专”的声母的第1个字母为z，名词代码n和z并在一起   |
| 27   | o    | 拟声词  | 取英语拟声词onomatopoeia的第1个字母。    |
| 28   | p    | 介词   | 取英语介词prepositional的第1个字母。    |
| 29   | q    | 量词   | 取英语quantity的第1个字母。           |
| 30   | r    | 代词   | 取英语代词pronoun的第2个字母,因p已用于介词。  |
| 31   | s    | 处所词  | 取英语space的第1个字母。              |
| 32   | t    | 时间词  | 取英语time的第1个字母。               |
| 33   | u    | 助词   | 取英语助词auxiliary               |
| 34   | v    | 动词   | 取英语动词verb的第一个字母。             |
| 35   | vd   | 副动词  | 直接作状语的动词。动词和副词的代码并在一起。       |
| 36   | vn   | 名动词  | 指具有名词功能的动词。动词和名词的代码并在一起      |
| 37   | w    | 标点符号 |                              |
| 38   | y    | 语气词  | 取汉字“语”的声母。                   |
| 39   | z    | 状态词  | 取汉字“状”的声母的前一个字母。             |

**返回示例**

```json
{"result_out": [
  {
    "length": 1,
    "word": "你好",
    "confidence": 1,
    "type": "v",
    "offset": 0
  },
  {
    "length": 1,
    "word": "百度",
    "confidence": 1,
    "type": "nz",
    "offset": 1
  }
]}
```

# 中文词向量表示

举例，传入一个词计算词的的词向量：

```
// 获取一个词的词向量
client.wordembedding('百度中国').then(function(result) {
	console.log(JSON.stringify(result));
});

```

**中文词向量表示 请求参数详情**

| 参数     | 类型     | 描述                                       | 是否必须 |
| :----- | :----- | :--------------------------------------- | :--- |
| word | String | 输入词                                  | 是    |
| dem | Int | 输查询维度。默认值0，对应1024维。（目前仅支持dem=0） | 否    |

**中文词向量表示 返回数据参数详情**

| 参数      | 类型     | 描述        |
| :------ | :----- | :-------- |
| word | String | 输入的文本内容     |
| vec    | array(double) | 	1024维的词向量表示      |

# 词相似度接口

举例，传入一个词计算词的的词向量：

```
// 获取一个词的词向量
client.wordSimEmbedding('百度', '中国百度').then(function(result) {
	console.log(JSON.stringify(result));
});

```

**中文词相似度 请求参数详情**

| 参数     | 类型     | 描述                                       | 是否必须 |
| :----- | :----- | :--------------------------------------- | :--- |
| word1 | String | 输入第一个词                                  | 是    |
| word2 | String | 输入第二个词                                  | 是    |

**中文词相似度 返回数据参数详情**

| 参数      | 类型     | 描述        |
| :------ | :----- | :-------- |
| score | double | 	相似度分数     |
| words | array(String) | 	输入的词列表, 数组第一项为第一个输入词，第二项为第二个输入此      |

# 情感倾向分析接口

举例，传入一个词分析情感倾向：

```
// 分析词的情感倾向
client.sentimentClassify('百度AI平台用起来不错').then(function(result) {
	console.log(JSON.stringify(result));
});

```

**情感倾向分析 请求参数详情**

| 参数     | 类型     | 描述                                       | 是否必须 |
| :----- | :----- | :--------------------------------------- | :--- |
| text | String | 输入词                                  | 是    |


**中情感倾向分析 返回数据参数详情**

| 参数      | 类型     | 描述        |
| :------ | :----- | :-------- |
| text | String | 	输入的文本内容    |
| items | array(object) | 	输入的词列表      |
| +sentiment | 	int | 	表示情感极性分类结果, 0:负向，1:中性，2:正向     |
| +confidence | 	float | 			表示分类的置信度    |
| +positive_prob | 	float | 		表示属于积极类别的概率    |
| +negative_prob | 	float | 			表示属于消极类别的概率    |

# 中文DNN语言模型

举例，传入短语，计算中文DNN语言模型：

```
client.dnnlmCn('百度是个搜索公司').then(function(result) {
    console.log(JSON.stringify(result));
});
```

**中文DNN语言模型 请求参数详情**

| 参数       | 类型     | 描述          | 是否必须 |
| :------- | :----- | :---------- | :--- |
| text | String | 输入的句子，不需要切词 | 是    |

**中文DNN语言模型 返回数据参数详情**

| 参数         | 类型       | 描述        |
| :--------- | :------- | :-------- |
| text        | String      | 	评论内容 |
| items    | array(object)   |      |
| +word    | string   | 切出的词     |
| +prob | float | 切词后每个词在句子中的概率值     |

# 短文本相似度

举例，传入两个短文本，计算相似度：

```
client.simnet('百度是个搜索公司', '谷歌是个搜索公司').then(function(result) {
    console.log('<simnet>: ' + JSON.stringify(result));
});
```

**短文本相似度 请求参数详情**

| 参数     | 类型     | 描述      | 是否必须 |
| :----- | :----- | :------ | :--- |
| query1 | String | 输入的第一个词 | 是    |
| query2 | String | 输入的第二个词 | 是    |

**短文本相似度 返回数据参数详情**

| 参数          | 类型     | 描述         |
| :---------- | :----- | :--------- |
| output      | object | 返回对象       |
| +score      | double | 两个文本相似度得分  |
| +type       | Int    | 默认为0       |
| +error      | Int    | 错误码        |
| +error-node | String | 错误码对应的文字说明 |

**错误码说明**

| Code | Message               | 返回说明      |
| ---- | --------------------- | --------- |
| 0    | NO\_ERROR             | 正确返回      |
| 1    | BEYOND\_SLOT\_LENGTH  | 输入长度过长    |
| 2    | OOV\_ERROR            | 输入文本不在词表中 |
| 3    | LEGO\_LIB\_RET\_ERROR | 内部库错误     |
| 4    | OTHER\_SERVER\_ERROR  | 其它服务错误    |
| 5    | INPUT\_HAS\_EMPTY     | 输入为空      |
| 6    | INPUT\_FORMAT\_ERROR  | 输入格式错误    |
| 7    | OTHER\_CLIENT\_ERROR  | 客服端错误     |


# 评论观点抽取

举例，传入评论文本，获取情感属性：

```
// 获取美食评论情感属性
client.commentTag('百度中国', 4).then(function(result) {
	console.log(JSON.stringify(result));
});

// 获取酒店评论情感属性
client.commentTag('百度中国', 1).then(function(result) {
	console.log(JSON.stringify(result));
});
```

**评论观点抽取 请求参数详情**

| 参数      | 类型          | 描述                                       | 是否必须 |
| :------ | :---------- | :--------------------------------------- | :--- |
| text | String      | 评论字符串                                    | 是    |
| type    | Int | 1: 酒店 2: KTV 3: 丽人 4: 美食（默认） 5: 旅游 6: 健康 7: 教育 8: 商业 9: 房产 10: 汽车 11: 生活 12: 购物 13: 3C| 否    |

**评论观点抽取 返回数据参数详情**

| 参数                  | 类型       | 描述                    |
| :------------------ | :------- | :-------------------- |
| items                | array(object) |                  |
| +prop                | String   | 评论标签(属性词+评论词)         |
| +adj                | String   | 评论标签(属性词+评论词)         |
| +sentiment                | int   | 该情感搭配的极性（0表示消极，1表示中性，2表示积极）        |
| +begin_pos                | int   | 该情感搭配在句子中的开始位置(GBK编码的字节偏移量）        |
| +end_pos                | int   | 该情感搭配在句子中的结束位置（GBK编码的字节偏移量）         |

# 词法分析

词法分析接口包含了中文分词和词性标注的功能，若需要使用中文分词或词性标注的功能，建议使用此接口。

举例，传入文本，获取词法分析结果：

```
client.lexer('百度是一家AI公司').then(function(result) {
	console.log(JSON.stringify(result));
});
```

**词法分析 请求参数详情**

| 参数    | 类型            | 描述                                  | 是否必须 |
| :---- | :------------ | :---------------------------------- | :--- |
| text | String | 待解析文本,长度不超过16KB | 是    |

**词法分析 返回数据参数详情**

| 参数名称           | 类型                | **必需** | 详细说明                                     |
| -------------- | ----------------- | ------ | ---------------------------------------- |
| text          | string            | 是      | 原始单条请求文本                                 |
| items         | array  of objects | 是      | 词汇数组，每个元素对应结果中的一个词                       |
| +item         | string            | 是      | 词汇的字符串                                   |
| +ne           | string            | 是      | 命名实体类型，命名实体识别算法使用。词性标注算法中，此项为空串          |
| +pos          | string            | 是      | 词性，词性标注算法使用。命名实体识别算法中，此项为空串              |
| +byte_offset  | int               | 是      | 在text中的字节级offset（使用GBK编码）                |
| +byte_length  | int               | 是      | 字节级length（使用GBK编码）                       |
| +uri          | string            | 否      | 链指到知识库的URI，只对命名实体有效。对于非命名实体和链接不到知识库的命名实体，此项为空串 |
| +formal       | string            | 否      | 词汇的标准化表达，主要针对时间、数字单位，没有归一化表达的，此项为空串      |
| +basic_words  | array of strings  | 是      | 基本词成分                                    |
| +loc_details  | array  of objects | 否      | 地址成分，非必需，仅对地址型命名实体有效，没有地址成分的，此项为空数组。     |
| ++type        | string            | 是      | 成分类型，如省、市、区、县                            |
| ++byte_offset | int               | 是      | 在item中的字节级offset（使用GBK编码）                |
| ++byte_length | int               | 是      | 字节级length（使用GBK编码）                       |

# 错误信息格式

若请求错误，服务器将返回的JSON文本包含以下参数：

* **error_code：**错误码；关于错误码的详细信息请参考**通用错误码**和**业务相关错误码**。
* **error_msg：**错误描述信息，帮助理解和解决发生的错误。

**服务端返回的错误码**

|error_code| error_msg | 备注 |
|---|---|---|
|282000 | internal error| 服务器内部错误，请再次请求， 如果持续出现此类错误，请通过QQ群（375765194）或工单联系技术支持团队。|
|282002 | input encoding error| 编码错误，请使用GBK编码 |
|282130 | no result |当前查询无结果返回，出现此问题的原因一般为：参数配置存在问题，请检查后重新尝试|
|282131 | input text too long |输入超限，内容请勿超过16KB	|
|282132 | invalid param | 请求中包含非法参数，请检查后重新尝试	|
|282133 | param {参数名} not exist |接口参数缺失 |
|282300 | word error | word不在算法词典中 |
|282301 | word\_1 error | word\_1提交的词汇暂未收录，无法比对相似度 |
|282302 | word\_2 error | word\_2提交的词汇暂未收录，无法比对相似度 |
|282303 | word\_1&word\_2 error | word\_1和word\_2暂未收录，无法比对相似度 |


# 版本更新记录

| 上线日期      | 版本号  | 更新内容                        |
| --------- | ---- | --------------------------- |
| 2017.5.26 | 1.0.0 | 初版					 |